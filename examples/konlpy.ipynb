{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## konlpy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from konlpy.tag import Okt\r\n",
    "# streamlit error \r\n",
    "# sol) update tweepy to 3.10.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "okt = Okt()\r\n",
    "\r\n",
    "# systemerror ( already loaded in another classloader\r\n",
    "# sol) In env\\konlpy\\jvm.py, every * to be deleted from folder_suffix\r\n",
    "# https://byeon-sg.tistory.com/entry/자연어-처리-konlpy-설치-오류-okt에러-already-loaded-in-another-classloader-SystemErro-1 [wave])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Pos-tagging(형태소 분석)\r\n",
    "text = '나는 코딩을 무지무지 좋아합니다!'\r\n",
    "okt.pos(text)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('나', 'Noun'),\n",
       " ('는', 'Josa'),\n",
       " ('코딩', 'Noun'),\n",
       " ('을', 'Josa'),\n",
       " ('무지무지', 'Adverb'),\n",
       " ('좋아합니다', 'Adjective'),\n",
       " ('!', 'Punctuation')]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "# Pos-tagging(형태소 분석)\r\n",
    "text = '나는 코딩을 무지무지 좋아합니다!'\r\n",
    "\r\n",
    "#pos와는 다르게 단순 나누기만함\r\n",
    "okt.morphs(text)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['나', '는', '코딩', '을', '무지무지', '좋아합니다', '!']"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "# Extracting Nouns\r\n",
    "\r\n",
    "text = '아이폰이랑 갤럭시중 어느 게 더 좋은 핸드폰이야??'\r\n",
    "okt.nouns(text)\r\n",
    "\r\n",
    "# 간혹 명사 이외의 것(게, 더)가 명사로 인식된다"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['아이폰', '갤럭시', '게', '더', '핸드폰']"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# 정규화 : 어지럽힌 문장을 깔끔하게 처리\r\n",
    "text = '안녕하세욬ㅋㅋㅋ 반가워요 샤릉해'\r\n",
    "print(okt.normalize(text))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "안녕하세요ㅋㅋㅋ 반가워요 사랑해\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BOW 실습"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "# bag of words\r\n",
    "# 간단하게 영어 단어 제거 => 정규화 및 필요 없는 단어, 특수문자 제거 => bow\r\n",
    "\r\n",
    "from konlpy.tag import Okt\r\n",
    "import re\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "okt = Okt()\r\n",
    "df = pd.read_excel('results.xlsx')\r\n",
    "df.info()\r\n",
    "df = df.fillna(' ')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47 entries, 0 to 46\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   comment    47 non-null     object\n",
      " 1   author     47 non-null     object\n",
      " 2   date       47 non-null     object\n",
      " 3   num_likes  47 non-null     int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "# 1. 필요 없는(이모티콘 등 의미 없는) 부분 전처리\r\n",
    "# 2. youtube comments에 @nickname~ 이런 경우가 있어, author column의 문자열들 모두 comments에서 모두 삭제해야 한다.\r\n",
    "\r\n",
    "# https://stackoverflow.com/questions/10968558/python-re-sub-with-a-list-of-words-to-find\r\n",
    "\r\n",
    "\r\n",
    "# 해결 : authors_regex에서 사전으로 특수문자 제거(메타 char 될 수 있는거) 제거 후, authors_regex부터 제거\r\n",
    "\r\n",
    "author = set()\r\n",
    "authors = set(['@' + re.sub('\\W+', '', i) for i in df['author']])\r\n",
    "authors_regex = \"|\".join(authors)\r\n",
    "\r\n",
    "for line in df['comment']:\r\n",
    "    line = re.sub('\\W+',' ', line)           # 특수 문자 스페이스로 대체.\r\n",
    "    line = re.sub(authors_regex, ' ', line)     # 특별한 의미 없는 단어 스페이스로 대체.\r\n",
    "\r\n",
    "comments = []\r\n",
    "for line in df['comment']:\r\n",
    "\r\n",
    "        line = re.sub(authors_regex, ' ', line)  # 댓글 중 tag한 거 다 제거\r\n",
    "        line = re.sub('\\W+',' ', line)           # 특수 문자 스페이스로 대체.\r\n",
    "        line = re.sub('\\d+',' ', line)         # 수치 스페이스로 대체.\r\n",
    "        line = re.sub('\\n',' ',line)             # line return 스페이스로 대체.\r\n",
    "        line = re.sub('[\\[\\]]', ' ',line)        # 대괄호 스페이스로 대체.\r\n",
    "        line = re.sub('[a-zA-Z]',' ',line)       # 영문 스페이스로 대체.\r\n",
    "        line = re.sub('[ㄱ-ㅎ | ㅏ-ㅣ]', ' ', line)     # 단모음, 단자음 스페이스로 대체.\r\n",
    "        line = re.sub('\\s+', ' ', line)          # 잉여 스페이즈 줄임.\r\n",
    "        # line = okt.normalize(line)            # 시간이 너무 걸림. 그리고 불필요한 작업\r\n",
    "        comments.append(line.strip())\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "print(authors_regex[:10])\r\n",
    "print(comments[:10])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "@jushan|@윤\n",
      "['진짜 기여워잉', '망고처럼 꽃돌이가 너무 귀엽네옇', '귀여운 새침이', '꽃돌이 남자에요 여자에오', '꽃돌이는 여자에요', '아 너무 귀여워', '제가 키웠던 토끼가 자기 집 위에 올라가서 못 내려오던 이유가 있었군요', '이쁜것 아휴 꽃돌이 관절 소즁해', '이꽃돌씨와 우리 깜토 까미토끼 가만나면 어덯게 될까요 큰토끼님 답글 부탁드려용', '꽃돌이는배고파 헉 감사해요 나중에 한번 될수있으면 꽃돌이보러갈께요']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "# COMMENT에서 명사, 형용사, 동사만 추출\r\n",
    "com_noun = {}\r\n",
    "com_verb = {}\r\n",
    "com_adj = {}\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "for com in comments:\r\n",
    "    tmp = okt.pos(com)\r\n",
    "\r\n",
    "    # 품사 태그를 통해 명, 형, 동 구분\r\n",
    "    for t in tmp:\r\n",
    "        word, tag = t[0], t[1]\r\n",
    "        if tag == 'Noun':\r\n",
    "            if word in com_noun:\r\n",
    "                com_noun[word] += 1\r\n",
    "            else:\r\n",
    "                com_noun[word] = 1\r\n",
    "\r\n",
    "        elif tag == 'Verb':\r\n",
    "            if word in com_verb:\r\n",
    "                com_verb[word] += 1\r\n",
    "            else:\r\n",
    "                com_verb[word] = 1\r\n",
    "\r\n",
    "        elif tag == 'Adjective':\r\n",
    "            if word in com_adj:\r\n",
    "                com_adj[word] += 1\r\n",
    "            else:\r\n",
    "                com_adj[word] = 1\r\n",
    "\r\n",
    "com_noun = sorted(list(com_noun.items()), key= lambda x: (x[1], x[0]), reverse=True)\r\n",
    "com_verb = sorted(list(com_verb.items()), key= lambda x: (x[1], x[0]), reverse=True)\r\n",
    "com_adj = sorted(list(com_adj.items()), key= lambda x: (x[1], x[0]), reverse=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "print(com_noun[:10])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('돌이', 18), ('꽃', 17), ('토끼', 10), ('수', 4), ('제', 3), ('이불', 3), ('위', 3), ('앞다리', 3), ('땐', 3), ('꽃돌', 3)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "print(com_verb[:10])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('큰', 4), ('해서', 2), ('않아', 2), ('만나면', 2), ('흘리는', 1), ('했는데', 1), ('해주면', 1), ('해주는', 1), ('해', 1), ('한다', 1)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "print(com_adj[:10])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('같은', 175), ('없는', 120), ('입니다', 112), ('있는', 93), ('이런', 86), ('나쁜', 84), ('같은데', 83), ('없다', 79), ('좋은', 73), ('많은', 71)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DTM & TFIDF"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "# dtm class\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "class DTM:\r\n",
    "    def __init__(self):\r\n",
    "        self.vocabulary = None\r\n",
    "\r\n",
    "\r\n",
    "    def dtm_build(self, comments):\r\n",
    "        comments_remake = []\r\n",
    "        col_word = set()\r\n",
    "\r\n",
    "        # 형태소 및 단어에서 단어 글자 크기가 1 이하이면 제외(sklearn과 동일하게 작동하도록 함)\r\n",
    "        for com in comments:\r\n",
    "            comments_remake.append([])\r\n",
    "            tmp = com.split()\r\n",
    "\r\n",
    "            for word in tmp:\r\n",
    "\r\n",
    "                word_re = okt.pos(word)\r\n",
    "                if len(word_re[0][0]) < 2:\r\n",
    "                    continue\r\n",
    "                col_word.add(word_re[0][0])\r\n",
    "                comments_remake[-1].append(word_re[0][0])\r\n",
    "        \r\n",
    "        col_word = list(col_word)\r\n",
    "\r\n",
    "        dtm = np.zeros(shape=(len(comments_remake), len(col_word)), dtype=np.int32) # row = comments, col = set of unique voca\r\n",
    "        \r\n",
    "        for i in range(len(comments_remake)):\r\n",
    "            comment = comments_remake[i]\r\n",
    "            for j in range(len(comment)):\r\n",
    "                word = comment[j]\r\n",
    "                if word in col_word:\r\n",
    "                    idx = col_word.index(word)\r\n",
    "                    dtm[i, idx] += 1\r\n",
    "\r\n",
    "\r\n",
    "        self.vocabulary = {i:word for i, word in enumerate(col_word)}\r\n",
    "        return dtm\r\n",
    "\r\n",
    "            \r\n",
    "dtm = DTM()\r\n",
    "new_dtm = dtm.dtm_build(comments)\r\n",
    "print(new_dtm)\r\n",
    "# print(dtm.vocabulary)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "\r\n",
    "comments_remake = []\r\n",
    "col_word = set()\r\n",
    "\r\n",
    "\r\n",
    "for com in comments:\r\n",
    "    tmp = com.split()\r\n",
    "    strs = []\r\n",
    "    for word in tmp:\r\n",
    "        word_re = okt.pos(word)\r\n",
    "        col_word.add(word_re[0][0])\r\n",
    "        strs.append(word_re[0][0])\r\n",
    "    comments_remake.append(' '.join(strs))\r\n",
    "    \r\n",
    "tfidfv = TfidfVectorizer().fit(comments_remake)\r\n",
    "tfidf_matrix = tfidfv.transform(comments_remake).toarray()\r\n",
    "voca_dict = tfidfv.vocabulary_\r\n",
    "\r\n",
    "\r\n",
    "for i in range(tfidf_matrix.shape[0]):\r\n",
    "    max_value = tfidf_matrix[i].argmax()\r\n",
    "    m = tfidf_matrix[i].max()\r\n",
    "    if  m > 0.7 and m < 1:\r\n",
    "        print(list(voca_dict.keys())[list(voca_dict.values()).index(max_value)], m)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "진짜 0.7422031318471273\n",
      "남자 0.7422031318471273\n",
      "귀여워 0.7856389514504228\n",
      "관절 0.7071067811865475\n",
      "나가요 0.7071067811865475\n",
      "동글동글 0.7071067811865475\n",
      "너무 0.8060093627548559\n",
      "아이쿠 0.7422031318471273\n",
      "귀여워 0.8420957014832894\n",
      "기여웡 0.8518852253129331\n",
      "짧은 0.7399133856298227\n",
      "뭉툭 0.8518852253129331\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('youtube_env': conda)"
  },
  "interpreter": {
   "hash": "d4bf65f30728a6096a7ad3883846392423ebe07b00f52cc917a4c2f9022e0877"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}