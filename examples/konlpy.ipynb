{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "# streamlit error \n",
    "# sol) update tweepy to 3.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "# systemerror ( already loaded in another classloader\n",
    "# sol) In env\\konlpy\\jvm.py, every * to be deleted from folder_suffix\n",
    "# https://byeon-sg.tistory.com/entry/ìì—°ì–´-ì²˜ë¦¬-konlpy-ì„¤ì¹˜-ì˜¤ë¥˜-oktì—ëŸ¬-already-loaded-in-another-classloader-SystemErro-1 [wave])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ë‚˜', 'Noun'),\n",
       " ('ëŠ”', 'Josa'),\n",
       " ('ì½”ë”©', 'Noun'),\n",
       " ('ì„', 'Josa'),\n",
       " ('ë¬´ì§€ë¬´ì§€', 'Adverb'),\n",
       " ('ì¢‹ì•„í•©ë‹ˆë‹¤', 'Adjective'),\n",
       " ('!', 'Punctuation')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pos-tagging(í˜•íƒœì†Œ ë¶„ì„)\n",
    "text = 'ë‚˜ëŠ” ì½”ë”©ì„ ë¬´ì§€ë¬´ì§€ ì¢‹ì•„í•©ë‹ˆë‹¤!'\n",
    "okt.pos(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ë‚˜', 'ëŠ”', 'ì½”ë”©', 'ì„', 'ë¬´ì§€ë¬´ì§€', 'ì¢‹ì•„í•©ë‹ˆë‹¤', '!']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pos-tagging(í˜•íƒœì†Œ ë¶„ì„)\n",
    "text = 'ë‚˜ëŠ” ì½”ë”©ì„ ë¬´ì§€ë¬´ì§€ ì¢‹ì•„í•©ë‹ˆë‹¤!'\n",
    "\n",
    "#posì™€ëŠ” ë‹¤ë¥´ê²Œ ë‹¨ìˆœ ë‚˜ëˆ„ê¸°ë§Œí•¨\n",
    "okt.morphs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ì•„ì´í°', 'ê°¤ëŸ­ì‹œ', 'ê²Œ', 'ë”', 'í•¸ë“œí°']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting Nouns\n",
    "\n",
    "text = 'ì•„ì´í°ì´ë‘ ê°¤ëŸ­ì‹œì¤‘ ì–´ëŠ ê²Œ ë” ì¢‹ì€ í•¸ë“œí°ì´ì•¼??'\n",
    "okt.nouns(text)\n",
    "\n",
    "# ê°„í˜¹ ëª…ì‚¬ ì´ì™¸ì˜ ê²ƒ(ê²Œ, ë”)ê°€ ëª…ì‚¬ë¡œ ì¸ì‹ëœë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”ã…‹ã…‹ã…‹ ë°˜ê°€ì›Œìš” ì‚¬ë‘í•´\n"
     ]
    }
   ],
   "source": [
    "# ì •ê·œí™” : ì–´ì§€ëŸ½íŒ ë¬¸ì¥ì„ ê¹”ë”í•˜ê²Œ ì²˜ë¦¬\n",
    "text = 'ì•ˆë…•í•˜ì„¸ìš¬ã…‹ã…‹ã…‹ ë°˜ê°€ì›Œìš” ìƒ¤ë¦‰í•´'\n",
    "print(okt.normalize(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOW ì‹¤ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47 entries, 0 to 46\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   comment    47 non-null     object\n",
      " 1   author     47 non-null     object\n",
      " 2   date       47 non-null     object\n",
      " 3   num_likes  47 non-null     int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# bag of words\n",
    "# ê°„ë‹¨í•˜ê²Œ ì˜ì–´ ë‹¨ì–´ ì œê±° => ì •ê·œí™” ë° í•„ìš” ì—†ëŠ” ë‹¨ì–´, íŠ¹ìˆ˜ë¬¸ì ì œê±° => bow\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "okt = Okt()\n",
    "df = pd.read_excel('results.xlsx')\n",
    "df.info()\n",
    "df = df.fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                             ì§„ì§œ ê¸°ì—¬ì›Œì‰ã… ã… \n",
      "1                                ë§ê³ ì²˜ëŸ¼ ê½ƒëŒì´ê°€ ë„ˆë¬´ ê·€ì—½ë„¤ì˜‡ã…ã…ã…ã…ã…\n",
      "2                                           ê·€ì—¬ìš´ ìƒˆì¹¨ì´ â¤â¤â¤\n",
      "3                                        ê½ƒëŒì´ ë‚¨ìì—ìš”? ì—¬ìì—ì˜¤\n",
      "4                                           ê½ƒëŒì´ëŠ” ì—¬ìì—ìš”~ğŸ˜„\n",
      "5                                              ì•„ ë„ˆë¬´ ê·€ì—¬ì›Œ\n",
      "6           ì œê°€ í‚¤ì› ë˜ í† ë¼ê°€ ìê¸° ì§‘ ìœ„ì— ì˜¬ë¼ê°€ì„œ ëª» ë‚´ë ¤ì˜¤ë˜ ì´ìœ ê°€ ìˆì—ˆêµ°ìš”...ã…‹\n",
      "7                                ì´ìœê²ƒ ã… ã… ì•„íœ´ ! ê½ƒëŒì´ ê´€ì ˆ ì†Œì¦í•´!\n",
      "8     ì´ê½ƒëŒì”¨ì™€ ìš°ë¦¬ ê¹œí† (ê¹Œë¯¸í† ë¼)ê°€ë§Œë‚˜ë©´ ì–´ë¯ê²Œ ë ê¹Œìš”?ã…‹ã…‹<br>í°í† ë¼ë‹˜!ë‹µê¸€ ë¶€íƒ...\n",
      "9     @ê½ƒëŒì´ëŠ”ë°°ê³ íŒŒ FlowerisHungry í—‰!ê°ì‚¬í•´ìš”!ã… ã… ë‚˜ì¤‘ì— í•œë²ˆ ë ìˆ˜ìˆìœ¼ë©´ ...\n",
      "10                        ê¹œí† ë‘ ë§Œë‚˜ë©´ ì¢‹ì€ ì¹œêµ¬ê°€ ë  ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”~ğŸ˜\n",
      "11                                  ê½ƒëŒ  ì™œ ì´ë ‡ê²Œ ê·€ì—¬ì›Œì„œ ë‚œë¦¬ì–‘ğŸ’•\n",
      "12    í† ë¼í•œí…Œ ë½€ë½€í•´ì£¼ë©´ ì‹«ë‹¤ê³  ì•ë°œë¡œ ë¯¸ëŠ”ë° ë‹¤ë¦¬ê°€ ì§§ì•„ì„œ ì§‘ì‚¬ëŠ” ê°™ì´ ë½€ë½€í•´ì£¼ëŠ” ê±¸ë¡œ...\n",
      "13       ê½ƒëŒì´ë„ ì´ë¶ˆì„ ì”¹ëŠ”êµ¬ë‚˜ ã…œã…œ í†¡í†¡í†¡í•˜ë©´ì„œ ë§ê°€ì§€ëŠ” ì´ë¶ˆë“¤ì´ ë‚¨ì•„ ë‚˜ì§ˆ ì•Šì•„..ã…œã…œ\n",
      "14                ë•ë¶„ì— ë§¤ ì‹œì¦Œ ìƒˆë¡œìš´ ì´ë¶ˆì„ ì‚´ ìˆ˜ ìˆë‹¤ëŠ” ì¥ì (?)ì´ ìˆìŠµë‹ˆë‹¤!\n",
      "15                                     ê½ƒëŒì´ ëª¸ë¬´ê²Œ ëª‡kg ë‚˜ê°€ìš”?\n",
      "16               @ê½ƒëŒì´ëŠ”ë°°ê³ íŒŒ FlowerisHungry ê½ƒëŒì´ê°€ ì‚´ì´ë§ì´ìª˜êµ°ìš”^^\n",
      "17                                          2.5kg ì…ë‹ˆë‹¤!ğŸ˜„\n",
      "18                                        ê½ƒëŒì´ëŠ” ì–¼êµ´ì´ ë™ê¸€ë™ê¸€\n",
      "19                                 ì•™ã„± ë„ˆë¬´ë„ˆë¬¸ ë„ˆë¬´ë„ˆë¬´ ê·€ì—¬ì›Œìš”ã… ã… ã… \n",
      "20                                              ì¡¸ê·€!!!!!\n",
      "21                                                ê·€ì—¬ì›Œìš”ì˜¤\n",
      "22                                ì¹¨ëŒ€ìœ„ì—ì„œ ë¬´ì—‡ì„ ì—´ì‹¬íˆ ê´€ì¸¡í•˜ëŠ”ê±¸ê¹Œìš”\n",
      "23                                            ê·¸ëŸ¬ê²Œë§ì´ì—ìš”~ğŸ˜„\n",
      "24                                            ì¸í˜•ì¸ê°€ìš” ã…œã… ğŸ’™\n",
      "25                                      ì•„ì´ì¿ ~!ê·€ì—¬ìš´ ê½‚ëŒì´â™¡â™¡â™¡\n",
      "26                                            ê·€ ê·€ì—¬ì›Œ...ğŸ¤©\n",
      "27    ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ì˜¬ë¼ê°ˆ ë• ê±°ì¹¨ì—†ì´ ì˜¬ë¼ê°€ì§€ë§Œ ë‚´ë ¤ì˜¬ ë• ì„¸ìƒ ì«„ë³´ë„ ê·¸ëŸ° ì«„ë³´...\n",
      "28               ...ë³¸ëŠ¥ì ìœ¼ë¡œ ê°€ì¥ í‘¹ì‹ í•œ ê³³ì„ ì°¾ì•„ì„œ ë‚´ë ¤ì™”êµ°ìš”. ë˜‘ë˜‘í•œ ë‡¨ì†!ğŸ˜\n",
      "29                 ê½ƒëŒì´ëŠ” ê·€ë„ ë„í†°í†µí†µí•œê²Œ ë„ˆë¬´ê·€ì—¬ì›Œìš”.. ì´ë¶ˆíƒ­ì€ ë§›ìˆë‹ˆ?ã…‹ã…‹ã…‹\n",
      "30    ì•ë‹¤ë¦¬ëŠ” ì§§ì§€ë§Œ ê·¸ ë•ì— ë¬´ì²™ì´ë‚˜ ê·€ì—½ê³  ì•™ì¦ë§ë‹¤ëŠ” ì‚¬ì‹¤. ë†’ì€ ê³³ ì¢‹ì•„í•˜ëŠ” ê±´ ì–´...\n",
      "31                  ì§§ì•„ì„œ ë„ˆë¬´ ê·€ì—¬ì›ŒğŸ¤—ğŸ˜˜ ê·¼ë° ë˜ ë†’ì€ ê³³ì€ ì¢‹ì•„í•˜ëŠ” ê½ƒëŒì´ ğŸ°ğŸ°\n",
      "32                          í°í† ë¼ë‹˜ğŸ¤¦ğŸ»â€â™€ï¸~~~ì—íœ´ ë‚˜ë¥¼ ë°Ÿê³  ê°€ì‹œì˜¤ğŸ˜‚ğŸ¤£ğŸ¤£\n",
      "33                                  ã… ã… ã… ã…  ê·€ì—¬ì›Œ ê·€ì—¬ì›Œ ã… ã… ã…  ì—‰ì—‰\n",
      "34                                         ì¥ì—”ì¥ ë„ˆë¬´ ê¸°ì—¬ì›¡..\n",
      "35                                            ì´ê½ƒëŒ ì‚¬ë‘í•´â™¡â™¡\n",
      "36                            ë‚´ë ¤ì˜¤ë‹¤ê°€ ê³¨ì ˆì´ë¼ë‹ˆ ã…œã…œ ë¶ˆìŒí•œ í† ë¼ë“¤ ã…œã…œ\n",
      "37                 êµ´í† ë¼ì˜ í›„ì˜ˆë¼ì„œ ì§§ì€ ì•ë‹¤ë¦¬ëŠ” ì–´ì©”ìˆ˜ì—†ì§€ë§Œ ê·€ì—¬ìš´ê±´ ëª»ì°¸ì§€ğŸ¤£ğŸ¤£ğŸ¤£\n",
      "38                                                ê·€ì«‘ê¸‹ ğŸ‡\n",
      "39                      ê½ƒëŒì´ ì¹¨ëŒ€ë¨¸ë¦¬ìª½ì—ì„œ ë¿…í•˜ê³  ê³ ê°œë‚´ë¯¸ëŠ”ê±° ë„ˆë¬´ ê·€ì—¬ì›Œìš©ğŸ’•\n",
      "40                                           ã…‹ã…‹íã… ã… ã… ê¸°ì—¬ì›Œì–´\n",
      "41                     ê½ƒëŒì´ ë•Œë¬¸ì— ì „ìŸë‚«ì–´ ì‚¬ë‘ìŠ¤ëŸ¬war... ê·€ì—¬war...\n",
      "42                 ì•ë‹¤ë¦¬ê°€ ì§§ì€ ê½ƒëŒì´ì™€ ë’·ë‹¤ë¦¬ê°€ ì§§ì€ í°í† ë¼ë‹˜ì˜ ì˜ìƒ ì˜ë´¤ìŠµë‹ˆë‹¤ğŸ˜„\n",
      "43    @ê½ƒëŒì´ëŠ”ë°°ê³ íŒŒ FlowerisHungry ìš¸ìŒì†Œë¦¬ë„ í† ë¼ë¥¼ ë‹®ì•„ê°€ì‹œëŠ” ëª¨ìŠµì´ ë³´ê¸°...\n",
      "44                                              ì´ì´ì´ìµ!!ğŸ˜¡\n",
      "45                                            ã……ã…‚ ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹\n",
      "46                                       ë­‰íˆ­í•œ ì…ì£¼ë³€ì´ ë„ˆë¬´ê·€ì—¬ì›€\n",
      "Name: comment, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. í•„ìš” ì—†ëŠ”(ì´ëª¨í‹°ì½˜ ë“± ì˜ë¯¸ ì—†ëŠ”) ë¶€ë¶„ ì „ì²˜ë¦¬\n",
    "# 2. youtube commentsì— @nickname~ ì´ëŸ° ê²½ìš°ê°€ ìˆì–´, author columnì˜ ë¬¸ìì—´ë“¤ ëª¨ë‘ commentsì—ì„œ ëª¨ë‘ ì‚­ì œí•´ì•¼ í•œë‹¤.\n",
    "\n",
    "# https://stackoverflow.com/questions/10968558/python-re-sub-with-a-list-of-words-to-find\n",
    "\n",
    "\n",
    "# í•´ê²° : authors_regexì—ì„œ ì‚¬ì „ìœ¼ë¡œ íŠ¹ìˆ˜ë¬¸ì ì œê±°(ë©”íƒ€ char ë  ìˆ˜ ìˆëŠ”ê±°) ì œê±° í›„, authors_regexë¶€í„° ì œê±°\n",
    "\n",
    "author = set()\n",
    "authors = set(['@' + re.sub('\\W+', ' ', i) for i in df['author']])\n",
    "authors_regex = \"|\".join(authors)\n",
    "\n",
    "for line in df['comment']:\n",
    "    line = re.sub('\\W+',' ', line)           # íŠ¹ìˆ˜ ë¬¸ì ìŠ¤í˜ì´ìŠ¤ë¡œ ëŒ€ì²´.\n",
    "    line = re.sub(authors_regex, ' ', line)     # íŠ¹ë³„í•œ ì˜ë¯¸ ì—†ëŠ” ë‹¨ì–´ ìŠ¤í˜ì´ìŠ¤ë¡œ ëŒ€ì²´.\n",
    "\n",
    "comments = []\n",
    "for line in df['comment']:\n",
    "\n",
    "        line = re.sub(authors_regex, ' ', line)  # ëŒ“ê¸€ ì¤‘ tagí•œ ê±° ë‹¤ ì œê±°\n",
    "        line = re.sub('\\W+',' ', line)           # íŠ¹ìˆ˜ ë¬¸ì ìŠ¤í˜ì´ìŠ¤ë¡œ ëŒ€ì²´.\n",
    "        line = re.sub('\\d+',' ', line)         # ìˆ˜ì¹˜ ìŠ¤í˜ì´ìŠ¤ë¡œ ëŒ€ì²´.\n",
    "        line = re.sub('\\n',' ',line)             # line return ìŠ¤í˜ì´ìŠ¤ë¡œ ëŒ€ì²´.\n",
    "        line = re.sub('[\\[\\]]', ' ',line)        # ëŒ€ê´„í˜¸ ìŠ¤í˜ì´ìŠ¤ë¡œ ëŒ€ì²´.\n",
    "        line = re.sub('[a-zA-Z]',' ',line)       # ì˜ë¬¸ ìŠ¤í˜ì´ìŠ¤ë¡œ ëŒ€ì²´.\n",
    "        line = re.sub('[ã„±-ã… | ã…-ã…£]', ' ', line)     # ë‹¨ëª¨ìŒ, ë‹¨ììŒ ìŠ¤í˜ì´ìŠ¤ë¡œ ëŒ€ì²´.\n",
    "        line = re.sub('\\s+', ' ', line)          # ì‰ì—¬ ìŠ¤í˜ì´ì¦ˆ ì¤„ì„.\n",
    "        # line = okt.normalize(line)            # ì‹œê°„ì´ ë„ˆë¬´ ê±¸ë¦¼. ê·¸ë¦¬ê³  ë¶ˆí•„ìš”í•œ ì‘ì—…\n",
    "        comments.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ì§„ì§œ ê¸°ì—¬ì›Œì‰', 'ë§ê³ ì²˜ëŸ¼ ê½ƒëŒì´ê°€ ë„ˆë¬´ ê·€ì—½ë„¤ì˜‡', 'ê·€ì—¬ìš´ ìƒˆì¹¨ì´', 'ê½ƒëŒì´ ë‚¨ìì—ìš” ì—¬ìì—ì˜¤', 'ê½ƒëŒì´ëŠ” ì—¬ìì—ìš”', 'ì•„ ë„ˆë¬´ ê·€ì—¬ì›Œ', 'ì œê°€ í‚¤ì› ë˜ í† ë¼ê°€ ìê¸° ì§‘ ìœ„ì— ì˜¬ë¼ê°€ì„œ ëª» ë‚´ë ¤ì˜¤ë˜ ì´ìœ ê°€ ìˆì—ˆêµ°ìš”', 'ì´ìœê²ƒ ì•„íœ´ ê½ƒëŒì´ ê´€ì ˆ ì†Œì¦í•´', 'ì´ê½ƒëŒì”¨ì™€ ìš°ë¦¬ ê¹œí†  ê¹Œë¯¸í† ë¼ ê°€ë§Œë‚˜ë©´ ì–´ë¯ê²Œ ë ê¹Œìš” í°í† ë¼ë‹˜ ë‹µê¸€ ë¶€íƒë“œë ¤ìš©', 'í—‰ ê°ì‚¬í•´ìš” ë‚˜ì¤‘ì— í•œë²ˆ ë ìˆ˜ìˆìœ¼ë©´ ê½ƒëŒì´ë³´ëŸ¬ê°ˆê»˜ìš”', 'ê¹œí† ë‘ ë§Œë‚˜ë©´ ì¢‹ì€ ì¹œêµ¬ê°€ ë  ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”', 'ê½ƒëŒ ì™œ ì´ë ‡ê²Œ ê·€ì—¬ì›Œì„œ ë‚œë¦¬ì–‘', 'í† ë¼í•œí…Œ ë½€ë½€í•´ì£¼ë©´ ì‹«ë‹¤ê³  ì•ë°œë¡œ ë¯¸ëŠ”ë° ë‹¤ë¦¬ê°€ ì§§ì•„ì„œ ì§‘ì‚¬ëŠ” ê°™ì´ ë½€ë½€í•´ì£¼ëŠ” ê±¸ë¡œ ì•Œê³  ì¢‹ì•„ ì£½ìŒ í† ë¼ëŠ” ê±°ì ˆ í–ˆëŠ”ë° ê³„ì†í•´ì„œ ë¹¡ì³ ì£½ìŒ', 'ê½ƒëŒì´ë„ ì´ë¶ˆì„ ì”¹ëŠ”êµ¬ë‚˜ í†¡í†¡í†¡í•˜ë©´ì„œ ë§ê°€ì§€ëŠ” ì´ë¶ˆë“¤ì´ ë‚¨ì•„ ë‚˜ì§ˆ ì•Šì•„', 'ë•ë¶„ì— ë§¤ ì‹œì¦Œ ìƒˆë¡œìš´ ì´ë¶ˆì„ ì‚´ ìˆ˜ ìˆë‹¤ëŠ” ì¥ì  ì´ ìˆìŠµë‹ˆë‹¤', 'ê½ƒëŒì´ ëª¸ë¬´ê²Œ ëª‡ ë‚˜ê°€ìš”', 'ê½ƒëŒì´ê°€ ì‚´ì´ë§ì´ìª˜êµ°ìš”', 'ì…ë‹ˆë‹¤', 'ê½ƒëŒì´ëŠ” ì–¼êµ´ì´ ë™ê¸€ë™ê¸€', 'ì•™ ë„ˆë¬´ë„ˆë¬¸ ë„ˆë¬´ë„ˆë¬´ ê·€ì—¬ì›Œìš”', 'ì¡¸ê·€', 'ê·€ì—¬ì›Œìš”ì˜¤', 'ì¹¨ëŒ€ìœ„ì—ì„œ ë¬´ì—‡ì„ ì—´ì‹¬íˆ ê´€ì¸¡í•˜ëŠ”ê±¸ê¹Œìš”', 'ê·¸ëŸ¬ê²Œë§ì´ì—ìš”', 'ì¸í˜•ì¸ê°€ìš”', 'ì•„ì´ì¿  ê·€ì—¬ìš´ ê½‚ëŒì´', 'ê·€ ê·€ì—¬ì›Œ', 'ì˜¬ë¼ê°ˆ ë• ê±°ì¹¨ì—†ì´ ì˜¬ë¼ê°€ì§€ë§Œ ë‚´ë ¤ì˜¬ ë• ì„¸ìƒ ì«„ë³´ë„ ê·¸ëŸ° ì«„ë³´ê°€ ì—†ëŠ”ê±° ë„ˆë¬´ ê³µê°ì´ì—ìš” ì €í¬ í† ë¼ë„ ì†ŒíŒŒ ìœ„ì— ì˜¬ë¼ê°€ëŠ”ê±¸ ì¢‹ì•„í•˜ëŠ”ë° ë§¤ë²ˆ ë‚´ë ¤ì˜¤ì§€ë¥¼ ëª»í•´ì„œ ì œê°€ ë°‘ì— ëˆ„ì›Œìˆì„ ë• í•­ìƒ í‘¹ì‹ í•œ ì œ ë±ƒì‚´ë¡œ ë›°ì–´ë‚´ë ¤ì˜¤ê³¤ í•´ìš”', 'ë³¸ëŠ¥ì ìœ¼ë¡œ ê°€ì¥ í‘¹ì‹ í•œ ê³³ì„ ì°¾ì•„ì„œ ë‚´ë ¤ì™”êµ°ìš” ë˜‘ë˜‘í•œ ë‡¨ì†', 'ê½ƒëŒì´ëŠ” ê·€ë„ ë„í†°í†µí†µí•œê²Œ ë„ˆë¬´ê·€ì—¬ì›Œìš” ì´ë¶ˆíƒ­ì€ ë§›ìˆë‹ˆ', 'ì•ë‹¤ë¦¬ëŠ” ì§§ì§€ë§Œ ê·¸ ë•ì— ë¬´ì²™ì´ë‚˜ ê·€ì—½ê³  ì•™ì¦ë§ë‹¤ëŠ” ì‚¬ì‹¤ ë†’ì€ ê³³ ì¢‹ì•„í•˜ëŠ” ê±´ ì–´ì©” ìˆ˜ ì—†ì§€ë§Œ ë‚´ë ¤ì˜¤ê¸° í˜ë“¤ë‹¤ ì‹¶ìœ¼ë©´ ê¼­ í°í† ë¼ë‹˜ ë„ì›€ì„ ë°›ì•„ì•¼ í•œë‹¤ í˜¼ìì„œ ë§‰ ë‚´ë ¤ì˜¤ë‹¤ ë‹¤ì¹˜ì§€ ë§ê³  ì†í†± í•˜ë‚˜ ë‹¤ì³ì„œ í”¼ í˜ë¦¬ëŠ” ëª¨ìŠµì¡°ì°¨ë„ ë³´ê³ ì‹¶ì§€ ì•Šì•„', 'ì§§ì•„ì„œ ë„ˆë¬´ ê·€ì—¬ì›Œ ê·¼ë° ë˜ ë†’ì€ ê³³ì€ ì¢‹ì•„í•˜ëŠ” ê½ƒëŒì´', 'í°í† ë¼ë‹˜ ì—íœ´ ë‚˜ë¥¼ ë°Ÿê³  ê°€ì‹œì˜¤', 'ê·€ì—¬ì›Œ ê·€ì—¬ì›Œ ì—‰ì—‰', 'ì¥ì—”ì¥ ë„ˆë¬´ ê¸°ì—¬ì›¡', 'ì´ê½ƒëŒ ì‚¬ë‘í•´', 'ë‚´ë ¤ì˜¤ë‹¤ê°€ ê³¨ì ˆì´ë¼ë‹ˆ ë¶ˆìŒí•œ í† ë¼ë“¤', 'êµ´í† ë¼ì˜ í›„ì˜ˆë¼ì„œ ì§§ì€ ì•ë‹¤ë¦¬ëŠ” ì–´ì©”ìˆ˜ì—†ì§€ë§Œ ê·€ì—¬ìš´ê±´ ëª»ì°¸ì§€', 'ê·€ì«‘ê¸‹', 'ê½ƒëŒì´ ì¹¨ëŒ€ë¨¸ë¦¬ìª½ì—ì„œ ë¿…í•˜ê³  ê³ ê°œë‚´ë¯¸ëŠ”ê±° ë„ˆë¬´ ê·€ì—¬ì›Œìš©', 'í ê¸°ì—¬ì›Œì–´', 'ê½ƒëŒì´ ë•Œë¬¸ì— ì „ìŸë‚«ì–´ ì‚¬ë‘ìŠ¤ëŸ¬ ê·€ì—¬', 'ì•ë‹¤ë¦¬ê°€ ì§§ì€ ê½ƒëŒì´ì™€ ë’·ë‹¤ë¦¬ê°€ ì§§ì€ í°í† ë¼ë‹˜ì˜ ì˜ìƒ ì˜ë´¤ìŠµë‹ˆë‹¤', 'ìš¸ìŒì†Œë¦¬ë„ í† ë¼ë¥¼ ë‹®ì•„ê°€ì‹œëŠ” ëª¨ìŠµì´ ë³´ê¸° íë­‡í•˜ê³  ê·¸ë ‡ë„¤ìš”', 'ì´ì´ì´ìµ', '', 'ë­‰íˆ­í•œ ì…ì£¼ë³€ì´ ë„ˆë¬´ê·€ì—¬ì›€']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMENTì—ì„œ ëª…ì‚¬, í˜•ìš©ì‚¬, ë™ì‚¬ë§Œ ì¶”ì¶œ\n",
    "com_noun = {}\n",
    "com_verb = {}\n",
    "com_adj = {}\n",
    "\n",
    "\n",
    "\n",
    "for com in comments:\n",
    "    tmp = okt.pos(com)\n",
    "\n",
    "    # í’ˆì‚¬ íƒœê·¸ë¥¼ í†µí•´ ëª…, í˜•, ë™ êµ¬ë¶„\n",
    "    for t in tmp:\n",
    "        word, tag = t[0], t[1]\n",
    "        if tag == 'Noun':\n",
    "            if word in com_noun:\n",
    "                com_noun[word] += 1\n",
    "            else:\n",
    "                com_noun[word] = 1\n",
    "\n",
    "        elif tag == 'Verb':\n",
    "            if word in com_verb:\n",
    "                com_verb[word] += 1\n",
    "            else:\n",
    "                com_verb[word] = 1\n",
    "\n",
    "        elif tag == 'Adjective':\n",
    "            if word in com_adj:\n",
    "                com_adj[word] += 1\n",
    "            else:\n",
    "                com_adj[word] = 1\n",
    "\n",
    "com_noun = sorted(list(com_noun.items()), key= lambda x: (x[1], x[0]), reverse=True)\n",
    "com_verb = sorted(list(com_verb.items()), key= lambda x: (x[1], x[0]), reverse=True)\n",
    "com_adj = sorted(list(com_adj.items()), key= lambda x: (x[1], x[0]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ëŒì´', 18), ('ê½ƒ', 17), ('í† ë¼', 10), ('ìˆ˜', 4), ('ì œ', 3), ('ì´ë¶ˆ', 3), ('ìœ„', 3), ('ì•ë‹¤ë¦¬', 3), ('ë•', 3), ('ê½ƒëŒ', 3)]\n"
     ]
    }
   ],
   "source": [
    "print(com_noun[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('í°', 4), ('í•´ì„œ', 2), ('ì•Šì•„', 2), ('ë§Œë‚˜ë©´', 2), ('í˜ë¦¬ëŠ”', 1), ('í–ˆëŠ”ë°', 1), ('í•´ì£¼ë©´', 1), ('í•´ì£¼ëŠ”', 1), ('í•´', 1), ('í•œë‹¤', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(com_verb[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ê°™ì€', 175), ('ì—†ëŠ”', 120), ('ì…ë‹ˆë‹¤', 112), ('ìˆëŠ”', 93), ('ì´ëŸ°', 86), ('ë‚˜ìœ', 84), ('ê°™ì€ë°', 83), ('ì—†ë‹¤', 79), ('ì¢‹ì€', 73), ('ë§ì€', 71)]\n"
     ]
    }
   ],
   "source": [
    "print(com_adj[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTM & TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# dtm class\n",
    "import numpy as np\n",
    "\n",
    "class DTM:\n",
    "    def __init__(self):\n",
    "        self.vocabulary = None\n",
    "\n",
    "\n",
    "    def dtm_build(self, comments):\n",
    "        comments_remake = []\n",
    "        col_word = set()\n",
    "\n",
    "        # í˜•íƒœì†Œ ë° ë‹¨ì–´ì—ì„œ ë‹¨ì–´ ê¸€ì í¬ê¸°ê°€ 1 ì´í•˜ì´ë©´ ì œì™¸(sklearnê³¼ ë™ì¼í•˜ê²Œ ì‘ë™í•˜ë„ë¡ í•¨)\n",
    "        for com in comments:\n",
    "            comments_remake.append([])\n",
    "            tmp = com.split()\n",
    "\n",
    "            for word in tmp:\n",
    "\n",
    "                word_re = okt.pos(word)\n",
    "                if len(word_re[0][0]) < 2:\n",
    "                    continue\n",
    "                col_word.add(word_re[0][0])\n",
    "                comments_remake[-1].append(word_re[0][0])\n",
    "        \n",
    "        col_word = list(col_word)\n",
    "\n",
    "        dtm = np.zeros(shape=(len(comments_remake), len(col_word)), dtype=np.int32) # row = comments, col = set of unique voca\n",
    "        \n",
    "        for i in range(len(comments_remake)):\n",
    "            comment = comments_remake[i]\n",
    "            for j in range(len(comment)):\n",
    "                word = comment[j]\n",
    "                if word in col_word:\n",
    "                    idx = col_word.index(word)\n",
    "                    dtm[i, idx] += 1\n",
    "\n",
    "\n",
    "        self.vocabulary = {i:word for i, word in enumerate(col_word)}\n",
    "        return dtm\n",
    "\n",
    "            \n",
    "dtm = DTM()\n",
    "new_dtm = dtm.dtm_build(comments)\n",
    "print(new_dtm)\n",
    "# print(dtm.vocabulary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§„ì§œ 0.7422031318471273\n",
      "ë‚¨ì 0.7422031318471273\n",
      "ê·€ì—¬ì›Œ 0.7856389514504228\n",
      "ê´€ì ˆ 0.7071067811865475\n",
      "ë‚˜ê°€ìš” 0.7071067811865475\n",
      "ë™ê¸€ë™ê¸€ 0.7071067811865475\n",
      "ë„ˆë¬´ 0.8060093627548559\n",
      "ì•„ì´ì¿  0.7422031318471273\n",
      "ê·€ì—¬ì›Œ 0.8420957014832894\n",
      "ê¸°ì—¬ì›¡ 0.8518852253129331\n",
      "ì§§ì€ 0.7399133856298227\n",
      "ë­‰íˆ­ 0.8518852253129331\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "comments_remake = []\n",
    "col_word = set()\n",
    "\n",
    "\n",
    "for com in comments:\n",
    "    tmp = com.split()\n",
    "    strs = []\n",
    "    for word in tmp:\n",
    "        word_re = okt.pos(word)\n",
    "        col_word.add(word_re[0][0])\n",
    "        strs.append(word_re[0][0])\n",
    "    comments_remake.append(' '.join(strs))\n",
    "    \n",
    "tfidfv = TfidfVectorizer().fit(comments_remake)\n",
    "tfidf_matrix = tfidfv.transform(comments_remake).toarray()\n",
    "voca_dict = tfidfv.vocabulary_\n",
    "\n",
    "\n",
    "for i in range(tfidf_matrix.shape[0]):\n",
    "    max_value = tfidf_matrix[i].argmax()\n",
    "    m = tfidf_matrix[i].max()\n",
    "    if  m > 0.7 and m < 1:\n",
    "        print(list(voca_dict.keys())[list(voca_dict.values()).index(max_value)], m)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4bf65f30728a6096a7ad3883846392423ebe07b00f52cc917a4c2f9022e0877"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('youtube_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
